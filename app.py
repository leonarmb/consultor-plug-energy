import streamlit as st
import google.generativeai as genai
import pandas as pd

# 1. Configura√ß√£o da P√°gina
st.set_page_config(page_title="Plug Energy - Consultor", page_icon="üîã", layout="centered")

# --- INTERFACE VISUAL (LOGO E T√çTULO) ---
@st.cache_data
def exibir_cabecalho():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        # Carrega o logo que voc√™ subiu no GitHub
        st.image("logo_plugenergy.png", use_container_width=True)
    st.markdown("<h1 style='text-align: center;'>Consultor T√©cnico de Engenharia</h1>", unsafe_allow_html=True)
    st.markdown("---")

exibir_cabecalho()

# --- GUIA DE USO (EXPANS√çVEL) ---
with st.expander("üìñ Orienta√ß√µes de Uso e Regras de Engenharia"):
    st.info("""
    **Como utilizar:**
    1. Descreva a carga total ou o modelo de nobreak desejado.
    2. O sistema aplicar√° automaticamente **20% de margem** sobre a carga.
    3. Para projetos de **Miss√£o Cr√≠tica**, solicite uma an√°lise de redund√¢ncia N+1.
    
    **Notas T√©cnicas:**
    - C√°lculos de autonomia baseados em baterias de 9Ah.
    - Prioridade para marca *Plug Energy* em contratos de loca√ß√£o.
    - Verifica√ß√£o de tens√£o (VDC) e compatibilidade el√©trica integrada.
    """)

# 2. Configura√ß√£o de Acesso via Secrets
try:
    API_KEY = st.secrets["GOOGLE_API_KEY"]
    # Configuramos o link que ser√° usado na fun√ß√£o de carga
    LINK_PLANILHA = st.secrets["LINK_PLANILHA_ESTOQUE"]
    
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-3-flash-preview')
except Exception as e:
    st.error("Erro de Configura√ß√£o: Certifique-se de que as chaves est√£o nos Secrets do Streamlit.")
    st.stop()

# 3. Carregamento MULTI-ABA (L√™ todo o Excel vivo)
@st.cache_data(ttl=60)
def carregar_estoque_total():
    try:
        # O pandas precisa do engine='openpyxl' para ler .xlsx direto da web
        dicionario_abas = pd.read_excel(LINK_PLANILHA, sheet_name=None, engine='openpyxl')
        
        texto_contexto = ""
        for nome_da_aba, df in dicionario_abas.items():
            # Limpa colunas e linhas vazias
            df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
            df = df.dropna(how='all')
            
            if not df.empty:
                texto_contexto += f"\n\n--- CATEGORIA: {nome_da_aba.upper()} ---\n"
                # Transformamos cada aba em CSV para a IA ler de forma leve
                texto_contexto += df.to_csv(index=False)
            
        return texto_contexto
    except Exception as e:
        st.error(f"Erro ao acessar a planilha: {e}")
        return None

# Chamada da fun√ß√£o para carregar os dados
contexto_estoque = carregar_estoque_total()

# 4. Interface de Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("Como posso ajudar a Plug Energy hoje?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        # SEGURAN√áA: S√≥ prossegue se o estoque foi carregado
        if contexto_estoque:
            full_prompt = f"""Voc√™ √© o Engenheiro Consultor S√™nior da Plug Energy do Brasil.
            Use os dados t√©cnicos abaixo (que abrangem Nobreaks, Baterias, Racks e Infraestrutura):
            
            {contexto_estoque}
            
            DIRETRIZES DE ENGENHARIA:
            - Aplique +20% de margem de carga sobre o valor informado pelo cliente.
            - Verifique rigorosamente a tens√£o de Entrada/Sa√≠da e o VDC informados na planilha.
            - N√£o assuma tens√µes padr√£o; reporte exatamente o que consta nos dados.
            - Priorize a marca Plug Energy para loca√ß√µes.
            - Se o usu√°rio pedir um sistema completo, procure itens compat√≠veis em todas as categorias.
            
            Pergunta do Usu√°rio: {prompt}"""
            
            placeholder = st.empty()
            full_response = ""
            
            try:
                response = model.generate_content(full_prompt, stream=True)
                for chunk in response:
                    full_response += chunk.text
                    placeholder.markdown(full_response + "‚ñå")
                placeholder.markdown(full_response)
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            except Exception as e:
                st.error(f"Erro na comunica√ß√£o com a IA: {e}")
        else:
            st.error("Erro Cr√≠tico: N√£o foi poss√≠vel ler a base de dados. Verifique o link no Secrets.")
