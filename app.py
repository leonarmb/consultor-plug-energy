import streamlit as st
import google.generativeai as genai
import pandas as pd

# 1. Configura√ß√£o da P√°gina
st.set_page_config(page_title="Plug Energy - Consultor", page_icon="üîã", layout="centered")
st.title("üîã Consultor T√©cnico Plug Energy")

# 2. Configura√ß√£o de Acesso (Chaves Diretas)
# Substituindo pelas suas chaves reais conforme solicitado
MINHA_API_KEY = "AIzaSyBqGtwQ6WRDs2z8hxzWHClqSRlqfwVz2WM"
MEU_LINK_CSV = "https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3NB1lKiPMuDYGflHluFFb1mJF1A31VUTzSBHh5YJtrM7MrgJ6EnZ8a95LifdS9Y5khRbNB-GbrNv-/pub?output=csv"

try:
    # Configura a IA com a sua chave do projeto BOTPLUGENERGY
    genai.configure(api_key=MINHA_API_KEY)
    
    # Define o modelo Gemini 3 (ajustado conforme o seu Playground)
    model = genai.GenerativeModel('gemini-3-flash-preview')
    
except Exception as e:
    st.error(f"Erro na configura√ß√£o da API: {e}")
    st.stop()

# 3. Carregamento do Estoque
@st.cache_data(ttl=300)
def carregar_dados():
    try:
        df = pd.read_csv(MEU_LINK_CSV)
        return df
    except Exception as e:
        st.error(f"Erro ao ler a planilha: {e}")
        return None

estoque_df = carregar_dados()

# 4. Intelig√™ncia do Consultor
if estoque_df is not None:
    contexto_estoque = estoque_df.to_string(index=False)
    
    # Suas instru√ß√µes de Engenharia do Playground
    instrucoes_engenharia = f"""
    CONTEXTO E IDENTIDADE: Voc√™ √© o Engenheiro Consultor de Vendas S√™nior da Plug Energy do Brasil. 
    DADOS DE ESTOQUE: {contexto_estoque}
    
    LOGICA DE ENGENHARIA:
    - Valida√ß√£o de Carga: Considere Consumo Total + 20% de margem.
    - Autonomia: Use a tabela de descarga de 9Ah para c√°lculos.
    - Upgrade: L√≥gica 1->3kVA e 6->10kVA (Entrega maior pelo pre√ßo do menor se necess√°rio).
    - Prioridade: Para loca√ß√£o, ofere√ßa sempre marca "Plug Energy".
    - Miss√£o Cr√≠tica: Sempre ofere√ßa cen√°rio de redund√¢ncia N+1.
    """

    # 5. Interface de Chat
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Como posso ajudar a Plug Energy hoje?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            try:
                # Gerando a resposta com Gemini 3
                full_prompt = f"{instrucoes_engenharia}\n\nUsu√°rio enviou os seguintes dados: {prompt}"
                response = model.generate_content(full_prompt)
                
                resposta_texto = response.text
                st.markdown(resposta_texto)
                st.session_state.messages.append({"role": "assistant", "content": resposta_texto})
            except Exception as e:
                st.error(f"Erro na resposta da IA: {e}")
else:
    st.warning("Verifique o link do CSV. O sistema n√£o conseguiu ler os dados.")
